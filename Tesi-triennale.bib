
@article{perlin_image_1985,
	title = {An image synthesizer},
	volume = {19},
	issn = {0097-8930},
	url = {https://dl.acm.org/doi/10.1145/325165.325247},
	doi = {10.1145/325165.325247},
	abstract = {We introduce the concept of a Pixel Stream Editor. This forms the basis for an interactive synthesizer for designing highly realistic Computer Generated Imagery. The designer works in an interactive Very High Level programming environment which provides a very fast concept/implement/view iteration cycle.Naturalistic visual complexity is built up by composition of non-linear functions, as opposed to the more conventional texture mapping or growth model algorithms. Powerful primitives are included for creating controlled stochastic effects. We introduce the concept of "solid texture" to the field of {CGI}.We have used this system to create very convincing representations of clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The algorithms created with this paradigm are generally extremely fast, highly realistic, and asynchronously parallelizable at the pixel level.},
	pages = {287--296},
	number = {3},
	journaltitle = {{SIGGRAPH} Comput. Graph.},
	author = {Perlin, Ken},
	urldate = {2025-05-26},
	date = {1985-07-01},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/IIBG4UN8/Perlin - 1985 - An image synthesizer.pdf:application/pdf},
}

@inproceedings{kim_large_2021,
	title = {Large Scale Multi-Illuminant ({LSMI}) Dataset for Developing White Balance Algorithm Under Mixed Illumination},
	url = {https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Large_Scale_Multi-Illuminant_LSMI_Dataset_for_Developing_White_Balance_Algorithm_ICCV_2021_paper.html},
	eventtitle = {Proceedings of the {IEEE}/{CVF} International Conference on Computer Vision},
	pages = {2410--2419},
	author = {Kim, Dongyoung and Kim, Jinwoo and Nam, Seonghyeon and Lee, Dongwoo and Lee, Yeonkyung and Kang, Nahyup and Lee, Hyong-Euk and Yoo, {ByungIn} and Han, Jae-Joon and Kim, Seon Joo},
	urldate = {2025-07-03},
	date = {2021},
	langid = {english},
	keywords = {local {AWB}, dataset, multi illuminant},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/6T6NRMWG/Kim et al. - 2021 - Large Scale Multi-Illuminant (LSMI) Dataset for Developing White Balance Algorithm Under Mixed Illum.pdf:application/pdf},
}

@article{zapryanov_automatic_2012,
	title = {Automatic White Balance Algorithms for Digital Still Cameras - a Comparative Study},
	url = {https://www.researchgate.net/publication/236941824_Automatic_White_Balance_Algorithms_for_Digital_Still_Cameras_-_a_Comparative_Study},
	abstract = {{PDF} {\textbar} Automatic white balance is an important function of digital still cameras. Failure to estimate illumination chromaticity correctly will result in... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	author = {Zapryanov, Georgi and Nikolova, Iva},
	urldate = {2025-07-03},
	date = {2012},
	langid = {english},
	keywords = {global {AWB}, {AWB} algorithm, soa},
	file = {k:/Users/alessandroteodori/Zotero/storage/4N32FVT9/AutomaticWhiteBalanceAlgorithmsforDigitalStillCameras-aComparativeStudy.pdf:application/pdf},
}

@article{huo_robust_2006,
	title = {Robust automatic white balance algorithm using gray color points in images},
	volume = {52},
	issn = {1558-4127},
	url = {https://ieeexplore.ieee.org/abstract/document/1649677},
	doi = {10.1109/TCE.2006.1649677},
	abstract = {A robust automatic white balance algorithm is proposed in this paper, using extracting gray color points in images for color temperature estimation. A gray color point is the point where R, G and B components are equivalent under the canonical light source. A little color deviation of the gray color point from gray under different color temperature is used to estimate the color temperature of the light source. The test results show that the proposed algorithm can provide a good perceive effect and has the advantage of easy realization, low complexity and robust convergence.},
	pages = {541--546},
	number = {2},
	journaltitle = {{IEEE} Transactions on Consumer Electronics},
	author = {Huo, Jun-yan and Chang, Yi-lin and Wang, Jing and Wei, Xiao-xia},
	urldate = {2025-07-03},
	date = {2006-05},
	keywords = {Cameras, Convergence, Face, Humans, Image segmentation, Light sources, Pixel, Robustness, Temperature, Testing, local {AWB}, {AWB} algorithm},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/XLC6UMUH/Huo et al. - 2006 - Robust automatic white balance algorithm using gray color points in images.pdf:application/pdf},
}

@article{thai_fast_2016,
	title = {A Fast White Balance Algorithm Based on Pixel Greyness},
	url = {https://www.researchgate.net/publication/308692177_A_Fast_White_Balance_Algorithm_Based_on_Pixel_Greyness},
	doi = {10.1007/s11760-016-0990-6},
	abstract = {{PDF} {\textbar} The goal of automatic white balance ({AWB}) is to maintain color constancy of an image by removing color cast caused by un-canonical illuminant. In... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	author = {Thai, Ba and Deng, Guang and Ross, Robert},
	urldate = {2025-07-03},
	date = {2016},
	langid = {english},
	keywords = {global {AWB}, {AWB} algorithm},
	file = {PDF:/Users/alessandroteodori/Zotero/storage/G99CN8DE/(PDF) A Fast White Balance Algorithm Based on Pixel Greyness.pdf:application/pdf},
}

@inproceedings{barron_fast_2017,
	title = {Fast Fourier Color Constancy},
	url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Barron_Fast_Fourier_Color_CVPR_2017_paper.html},
	eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {886--894},
	author = {Barron, Jonathan T. and Tsai, Yun-Ta},
	urldate = {2025-07-03},
	date = {2017},
	keywords = {ml, {AWB} algorithm, video},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/NLAT4DLA/Barron e Tsai - 2017 - Fast Fourier Color Constancy.pdf:application/pdf},
}

@article{serteep_white_nodate,
	title = {White balance techniques of digital image},
	url = {https://www.researchgate.net/publication/385851574_Corresponding_author_Hind_Jumaa_Serteep_Subject_review_White_balance_techniques_of_digital_image},
	doi = {10.30574/gjeta.2024.20.1.0129},
	shorttitle = {({PDF}) * Corresponding author},
	abstract = {{PDF} {\textbar} Due to un control environment during creating of the digital image make the resulting image have un real color cast, for that a white balance... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	journaltitle = {{ResearchGate}},
	author = {Serteep, Hind Jumaa},
	urldate = {2025-07-03},
	langid = {english},
	keywords = {{AWB} algorithm, soa},
	file = {Full text:/Users/alessandroteodori/Zotero/storage/TN3L28LN/(PDF)  Corresponding author Hind Jumaa Serteep Subject review White balance techniques of digital.pdf:application/pdf;GJETA-2024-0129:/Users/alessandroteodori/Zotero/storage/H2HK73HX/GJETA-2024-0129.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/G4HC26CP/385851574_Corresponding_author_Hind_Jumaa_Serteep_Subject_review_White_balance_techniques_of_di.html:text/html},
}

@article{buzzelli_analysis_2023,
	title = {Analysis of biases in automatic white balance datasets and methods},
	volume = {48},
	rights = {Â© 2022 The Authors. Color Research and Application published by Wiley Periodicals {LLC}.},
	issn = {1520-6378},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/col.22822},
	doi = {10.1002/col.22822},
	abstract = {Annotated datasets for automatic white balance ({AWB}) are used for the evaluation and, when necessary, the training, of {AWB} methods. Relying on such datasets requires awareness of the potential bias in their content and characteristics: some methods are designed to rely on the presence of particular elements, such as human skin, while other methods learn implicit relationships between image content and light properties from training data. The dependency on these relationships makes it fundamental to understand whether the available datasets are actually representative of common application scenarios, such as the presence of human subjects, the diversity of composition, or the illumination conditions. In this paper we overview the most common datasets for Automatic White Balance, including those for single as well as multiple illuminant estimation, providing a critical analysis on their characteristics. Furthermore, we identify a number of existing methods for single illuminant estimation, as a representative pool of approaches to the problem with various levels of complexity. We investigate how the performance of these correlate to the image content of common datasets.},
	pages = {40--62},
	number = {1},
	journaltitle = {Color Research \& Application},
	author = {Buzzelli, Marco and Zini, Simone and Bianco, Simone and Ciocca, Gianluigi and Schettini, Raimondo and Tchobanou, Mikhail K.},
	urldate = {2025-07-03},
	date = {2023},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/col.22822},
	keywords = {dataset, soa, automatic white balance, color constancy, dataset analysis, illuminant estimation},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/KXK2QIBB/Buzzelli et al. - 2023 - Analysis of biases in automatic white balance datasets and methods.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/CCZNTYMW/col.html:text/html},
}

@inproceedings{afifi_auto_2022,
	title = {Auto White-Balance Correction for Mixed-Illuminant Scenes},
	url = {https://openaccess.thecvf.com/content/WACV2022/html/Afifi_Auto_White-Balance_Correction_for_Mixed-Illuminant_Scenes_WACV_2022_paper.html},
	eventtitle = {Proceedings of the {IEEE}/{CVF} Winter Conference on Applications of Computer Vision},
	pages = {1210--1219},
	author = {Afifi, Mahmoud and Brubaker, Marcus A. and Brown, Michael S.},
	urldate = {2025-07-03},
	date = {2022},
	langid = {english},
	keywords = {{AWB} algorithm},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/Y6D9E9Y9/Afifi et al. - 2022 - Auto White-Balance Correction for Mixed-Illuminant Scenes.pdf:application/pdf},
}

@inproceedings{chiou_automatic_2002,
	title = {Automatic white balance for digital still camera},
	url = {https://www.csie.ntu.edu.tw/~fuh/personal/CAIA2002.AutomaticWhiteBalanceforDigital.pdf},
	pages = {475--480},
	booktitle = {Proceedings of Conference on Artificial Intelligence and Applications},
	author = {Chiou, Tzan-Sheng and Fuh, Chiou-Shann and Chikane, Varsha},
	urldate = {2025-07-03},
	date = {2002},
	keywords = {{AWB} algorithm},
	file = {Available Version (via Google Scholar):/Users/alessandroteodori/Zotero/storage/IHLV8W9S/Chiou et al. - 2002 - Automatic white balance for digital still camera.pdf:application/pdf},
}

@misc{wei_integral_2025,
	title = {Integral Fast Fourier Color Constancy},
	url = {http://arxiv.org/abs/2502.03494},
	doi = {10.48550/arXiv.2502.03494},
	abstract = {Traditional auto white balance ({AWB}) algorithms typically assume a single global illuminant source, which leads to color distortions in multi-illuminant scenes. While recent neural network-based methods have shown excellent accuracy in such scenarios, their high parameter count and computational demands limit their practicality for real-time video applications. The Fast Fourier Color Constancy ({FFCC}) algorithm was proposed for single-illuminant-source scenes, predicting a global illuminant source with high efficiency. However, it cannot be directly applied to multi-illuminant scenarios unless specifically modified. To address this, we propose Integral Fast Fourier Color Constancy ({IFFCC}), an extension of {FFCC} tailored for multi-illuminant scenes. {IFFCC} leverages the proposed integral {UV} histogram to accelerate histogram computations across all possible regions in Cartesian space and parallelizes Fourier-based convolution operations, resulting in a spatially-smooth illumination map. This approach enables high-accuracy, real-time {AWB} in multi-illuminant scenes. Extensive experiments show that {IFFCC} achieves accuracy that is on par with or surpasses that of pixel-level neural networks, while reducing the parameter count by over \$400{\textbackslash}times\$ and processing speed by 20 - \$100{\textbackslash}times\$ faster than network-based approaches.},
	number = {{arXiv}:2502.03494},
	publisher = {{arXiv}},
	author = {Wei, Wenjun and Qian, Yanlin and Chen, Huaian and Dai, Junkang and Jin, Yi},
	urldate = {2025-07-08},
	date = {2025-02-05},
	eprinttype = {arxiv},
	eprint = {2502.03494 [eess]},
	keywords = {global {AWB}, {AWB} algorithm, video, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Preprint PDF:/Users/alessandroteodori/Zotero/storage/S95S6S4A/Wei et al. - 2025 - Integral Fast Fourier Color Constancy.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/2IJIWWUM/2502.html:text/html},
}

@misc{akazawa_spatially_2021,
	title = {Spatially varying white balancing for mixed and non-uniform illuminants},
	url = {http://arxiv.org/abs/2109.01350},
	doi = {10.48550/arXiv.2109.01350},
	abstract = {In this paper, we propose a novel white balance adjustment, called "spatially varying white balancing," for single, mixed, and non-uniform illuminants. By using n diagonal matrices along with a weight, the proposed method can reduce lighting effects on all spatially varying colors in an image under such illumination conditions. In contrast, conventional white balance adjustments do not consider the correcting of all colors except under a single illuminant. Also, multi-color balance adjustments can map multiple colors into corresponding ground truth colors, although they may cause the rank deficiency problem to occur as a non-diagonal matrix is used, unlike white balancing. In an experiment, the effectiveness of the proposed method is shown under mixed and non-uniform illuminants, compared with conventional white and multi-color balancing. Moreover, under a single illuminant, the proposed method has almost the same performance as the conventional white balancing.},
	number = {{arXiv}:2109.01350},
	publisher = {{arXiv}},
	author = {Akazawa, Teruaki and Kinoshita, Yuma and Kiya, Hitoshi},
	urldate = {2025-07-08},
	date = {2021-09-03},
	eprinttype = {arxiv},
	eprint = {2109.01350 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/Users/alessandroteodori/Zotero/storage/5L6Y3U5Y/Akazawa et al. - 2021 - Spatially varying white balancing for mixed and non-uniform illuminants.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/Q2Q35R4W/2109.html:text/html},
}

@inproceedings{hui_white_2016,
	title = {White balance under mixed illumination using flash photography},
	url = {https://ieeexplore.ieee.org/abstract/document/7492879/?casa_token=Eoq0h3p5puoAAAAA:EDQtOVd5JbzocFXOJK2uD-gegYGIKJd0t7LQFNPwJW9Ijnn_4ZxYSF-CtkHiRJMPCpisI8cMVVGE},
	pages = {1--10},
	booktitle = {2016 {IEEE} International Conference on Computational Photography ({ICCP})},
	publisher = {{IEEE}},
	author = {Hui, Zhuo and Sankaranarayanan, Aswin C. and Sunkavalli, Kalyan and Hadap, Sunil},
	urldate = {2025-07-08},
	date = {2016},
	file = {PDF:/Users/alessandroteodori/Zotero/storage/4LJIVWH6/Hui et al. - 2016 - White balance under mixed illumination using flash photography.pdf:application/pdf},
}

@article{ershov_cube_2020,
	title = {The Cube++ Illumination Estimation Dataset},
	volume = {8},
	issn = {2169-3536},
	url = {http://arxiv.org/abs/2011.10028},
	doi = {10.1109/ACCESS.2020.3045066},
	abstract = {Computational color constancy has the important task of reducing the influence of the scene illumination on the object colors. As such, it is an essential part of the image processing pipelines of most digital cameras. One of the important parts of the computational color constancy is illumination estimation, i.e. estimating the illumination color. When an illumination estimation method is proposed, its accuracy is usually reported by providing the values of error metrics obtained on the images of publicly available datasets. However, over time it has been shown that many of these datasets have problems such as too few images, inappropriate image quality, lack of scene diversity, absence of version tracking, violation of various assumptions, {GDPR} regulation violation, lack of additional shooting procedure info, etc. In this paper, a new illumination estimation dataset is proposed that aims to alleviate many of the mentioned problems and to help the illumination estimation research. It consists of 4890 images with known illumination colors as well as with additional semantic data that can further make the learning process more accurate. Due to the usage of the {SpyderCube} color target, for every image there are two ground-truth illumination records covering different directions. Because of that, the dataset can be used for training and testing of methods that perform single or two-illuminant estimation. This makes it superior to many similar existing datasets. The datasets, it's smaller version {SimpleCube}++, and the accompanying code are available at https://github.com/Visillect/{CubePlusPlus}/.},
	pages = {227511--227527},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Ershov, Egor and Savchik, Alex and Semenkov, Illya and BaniÄ, Nikola and Belokopytov, Alexander and Senshina, Daria and KosceviÄ, Karlo and SubaÅ¡iÄ, Marko and LonÄariÄ, Sven},
	urldate = {2025-07-08},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {2011.10028 [cs]},
	keywords = {dataset, Computer Science - Computer Vision and Pattern Recognition, single illuminant, multiple illuminations},
	file = {Preprint PDF:/Users/alessandroteodori/Zotero/storage/B6TXYV39/Ershov et al. - 2020 - The Cube++ Illumination Estimation Dataset.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/BIN2QJCK/2011.html:text/html},
}

@misc{laakom_intel-tau_2020,
	title = {{INTEL}-{TAU}: A Color Constancy Dataset},
	url = {http://arxiv.org/abs/1910.10404},
	doi = {10.48550/arXiv.1910.10404},
	shorttitle = {{INTEL}-{TAU}},
	abstract = {In this paper, we describe a new large dataset for illumination estimation. This dataset, called {INTEL}-{TAU}, contains 7022 images in total, which makes it the largest available high-resolution dataset for illumination estimation research. The variety of scenes captured using three different camera models, namely Canon 5DSR, Nikon D810, and Sony {IMX}135, makes the dataset appropriate for evaluating the camera and scene invariance of the different illumination estimation techniques. Privacy masking is done for sensitive information, e.g., faces. Thus, the dataset is coherent with the new General Data Protection Regulation ({GDPR}). Furthermore, the effect of color shading for mobile images can be evaluated with {INTEL}-{TAU} dataset, as both corrected and uncorrected versions of the raw data are provided. Furthermore, this paper benchmarks several color constancy approaches on the proposed dataset.},
	number = {{arXiv}:1910.10404},
	publisher = {{arXiv}},
	author = {Laakom, Firas and Raitoharju, Jenni and Iosifidis, Alexandros and Nikkanen, Jarno and Gabbouj, Moncef},
	urldate = {2025-07-08},
	date = {2020-12-23},
	eprinttype = {arxiv},
	eprint = {1910.10404 [eess]},
	keywords = {global {AWB}, dataset, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Computer Vision and Pattern Recognition, single illuminant},
	file = {Preprint PDF:/Users/alessandroteodori/Zotero/storage/D3DRVHLT/Laakom et al. - 2020 - INTEL-TAU A Color Constancy Dataset.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/HJG3FZRX/1910.html:text/html},
}

@misc{murmann_dataset_2019,
	title = {A Dataset of Multi-Illumination Images in the Wild},
	url = {http://arxiv.org/abs/1910.08131},
	doi = {10.48550/arXiv.1910.08131},
	abstract = {Collections of images under a single, uncontrolled illumination have enabled the rapid advancement of core computer vision tasks like classification, detection, and segmentation. But even with modern learning techniques, many inverse problems involving lighting and material understanding remain too severely ill-posed to be solved with single-illumination datasets. To fill this gap, we introduce a new multi-illumination dataset of more than 1000 real scenes, each captured under 25 lighting conditions. We demonstrate the richness of this dataset by training state-of-the-art models for three challenging applications: single-image illumination estimation, image relighting, and mixed-illuminant white balance.},
	number = {{arXiv}:1910.08131},
	publisher = {{arXiv}},
	author = {Murmann, Lukas and Gharbi, Michael and Aittala, Miika and Durand, Fredo},
	urldate = {2025-07-08},
	date = {2019-10-17},
	eprinttype = {arxiv},
	eprint = {1910.08131 [cs]},
	keywords = {dataset, Computer Science - Computer Vision and Pattern Recognition, single illuminant, multiple illuminations},
	file = {Preprint PDF:/Users/alessandroteodori/Zotero/storage/Q57B2HWE/Murmann et al. - 2019 - A Dataset of Multi-Illumination Images in the Wild.pdf:application/pdf;Snapshot:/Users/alessandroteodori/Zotero/storage/ZUPRDUTG/1910.html:text/html},
}

@inproceedings{hu_fc4_2017,
	title = {{FC}4: Fully Convolutional Color Constancy With Confidence-Weighted Pooling},
	url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Hu_FC4_Fully_Convolutional_CVPR_2017_paper.html},
	shorttitle = {{FC}4},
	eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {4085--4094},
	author = {Hu, Yuanming and Wang, Baoyuan and Lin, Stephen},
	urldate = {2025-07-15},
	date = {2017},
	keywords = {{AWB} algorithm},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/36HZCI3K/Hu et al. - 2017 - FC4 Fully Convolutional Color Constancy With Confidence-Weighted Pooling.pdf:application/pdf},
}

@inproceedings{afifi_deep_2020,
	title = {Deep White-Balance Editing},
	url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Afifi_Deep_White-Balance_Editing_CVPR_2020_paper.html},
	eventtitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	pages = {1397--1406},
	author = {Afifi, Mahmoud and Brown, Michael S.},
	urldate = {2025-07-15},
	date = {2020},
	keywords = {ml, {AWB} algorithm},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/7LX8KECI/Afifi e Brown - 2020 - Deep White-Balance Editing.pdf:application/pdf},
}

@inproceedings{afifi_when_2019,
	title = {When Color Constancy Goes Wrong: Correcting Improperly White-Balanced Images},
	url = {https://openaccess.thecvf.com/content_CVPR_2019/html/Afifi_When_Color_Constancy_Goes_Wrong_Correcting_Improperly_White-Balanced_Images_CVPR_2019_paper.html},
	shorttitle = {When Color Constancy Goes Wrong},
	eventtitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	pages = {1535--1544},
	author = {Afifi, Mahmoud and Price, Brian and Cohen, Scott and Brown, Michael S.},
	urldate = {2025-07-15},
	date = {2019},
	keywords = {ml, {AWB} algorithm},
	file = {Full Text PDF:/Users/alessandroteodori/Zotero/storage/N3EJ8R6Z/Afifi et al. - 2019 - When Color Constancy Goes Wrong Correcting Improperly White-Balanced Images.pdf:application/pdf},
}

@inproceedings{gehler_bayesian_2008,
	title = {Bayesian color constancy revisited (colorchecker)},
	url = {https://ieeexplore.ieee.org/abstract/document/4587765/},
	pages = {1--8},
	booktitle = {2008 {IEEE} Conference on Computer Vision and Pattern Recognition},
	publisher = {{IEEE}},
	author = {Gehler, Peter Vincent and Rother, Carsten and Blake, Andrew and Minka, Tom and Sharp, Toby},
	urldate = {2025-07-16},
	date = {2008},
	keywords = {dataset},
	file = {Available Version (via Google Scholar):/Users/alessandroteodori/Zotero/storage/89BZYQPG/Gehler et al. - 2008 - Bayesian color constancy revisited.pdf:application/pdf},
}

@article{ciurea_large_2003,
	title = {A large image database for color constancy research},
	url = {https://summit.sfu.ca/item/18270},
	author = {Ciurea, Florian and Funt, Brian},
	urldate = {2025-07-16},
	date = {2003},
	note = {Publisher: Simon Fraser University},
	keywords = {dataset},
	file = {Available Version (via Google Scholar):/Users/alessandroteodori/Zotero/storage/5C3HXIME/Ciurea e Funt - 2003 - A large image database for color constancy research.pdf:application/pdf},
}

@article{cheng_illuminant_2014,
	title = {Illuminant estimation for color constancy: why spatial-domain methods work and the role of the color distribution},
	volume = {31},
	url = {https://opg.optica.org/abstract.cfm?uri=josaa-31-5-1049},
	shorttitle = {Illuminant estimation for color constancy},
	pages = {1049--1058},
	number = {5},
	journaltitle = {Journal of the Optical Society of America A},
	author = {Cheng, Dongliang and Prasad, Dilip K. and Brown, Michael S.},
	urldate = {2025-07-16},
	date = {2014},
	note = {Publisher: Optical Society of America},
	keywords = {dataset},
	file = {PDF:/Users/alessandroteodori/Zotero/storage/AGLHTVJN/Cheng et al. - 2014 - Illuminant estimation for color constancy why spatial-domain methods work and the role of the color.pdf:application/pdf},
}

@inproceedings{beigpour_comprehensive_2015,
	title = {A comprehensive multi-illuminant dataset for benchmarking of the intrinsic image algorithms},
	url = {http://openaccess.thecvf.com/content_iccv_2015/html/Beigpour_A_Comprehensive_Multi-Illuminant_ICCV_2015_paper.html},
	pages = {172--180},
	booktitle = {Proceedings of the {IEEE} International Conference on Computer Vision},
	author = {Beigpour, Shida and Kolb, Andreas and Kunz, Sven},
	urldate = {2025-07-16},
	date = {2015},
	keywords = {dataset},
	file = {Available Version (via Google Scholar):/Users/alessandroteodori/Zotero/storage/BGZM8X53/Beigpour et al. - 2015 - A comprehensive multi-illuminant dataset for benchmarking of the intrinsic image algorithms.pdf:application/pdf},
}

@article{beigpour_multi-illuminant_2013,
	title = {Multi-illuminant estimation with conditional random fields},
	volume = {23},
	url = {https://ieeexplore.ieee.org/abstract/document/6637091/?casa_token=bSB3d--iBu0AAAAA:0TlfqAfh38YRtHLERivT4L5PuO_AZwihaoQawbpZbsrTBXpqo-sY_aBNVwPtBVfVN1D2uDpRisIP},
	pages = {83--96},
	number = {1},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Beigpour, Shida and Riess, Christian and Van De Weijer, Joost and Angelopoulou, Elli},
	urldate = {2025-07-16},
	date = {2013},
	note = {Publisher: {IEEE}},
	keywords = {dataset},
	file = {PDF:/Users/alessandroteodori/Zotero/storage/PWQNA8V2/Beigpour et al. - 2013 - Multi-illuminant estimation with conditional random fields.pdf:application/pdf},
}

@inproceedings{aghaei_flying_2020,
	title = {A flying gray ball multi-illuminant image dataset for color research},
	volume = {28},
	url = {https://library.imaging.org/cic/articles/28/1/art00023},
	pages = {142--149},
	booktitle = {Color and Imaging Conference},
	publisher = {Society for Imaging Science and Technology},
	author = {Aghaei, Hoda and Funt, Brian},
	urldate = {2025-07-16},
	date = {2020},
	keywords = {dataset},
	file = {Available Version (via Google Scholar):/Users/alessandroteodori/Zotero/storage/8ZX6LZHS/Aghaei e Funt - 2020 - A flying gray ball multi-illuminant image dataset for color research.pdf:application/pdf},
}

@inproceedings{weng_novel_2005,
	title = {A novel automatic white balance method for digital still cameras},
	url = {https://ieeexplore.ieee.org/abstract/document/1465458/?casa_token=phQ2g4yWSZ4AAAAA:e5OrFu_NYPzW0UEmkkdis6BaO8oLGQbYcoZGpBWPEo6w5jLBb_OUSDxHZf4KRqWCfMf2O5LCYg},
	pages = {3801--3804},
	booktitle = {2005 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	publisher = {{IEEE}},
	author = {Weng, Ching-Chih and Chen, Homer and Fuh, Chiou-Shann},
	urldate = {2025-08-24},
	date = {2005},
	keywords = {{AWB} algorithm},
}

@article{van_de_weijer_edge-based_2007,
	title = {Edge-based color constancy},
	volume = {16},
	url = {https://ieeexplore.ieee.org/abstract/document/4287009/},
	pages = {2207--2214},
	number = {9},
	journaltitle = {{IEEE} Transactions on image processing},
	author = {Van De Weijer, Joost and Gevers, Theo and Gijsenij, Arjan},
	urldate = {2025-08-24},
	date = {2007},
	note = {Publisher: {IEEE}},
	file = {Available Version (via Google Scholar):/Users/alessandroteodori/Zotero/storage/SHK4EMHL/Van De Weijer et al. - 2007 - Edge-based color constancy.pdf:application/pdf},
}

@article{domislovic_shadows_2023,
	title = {Shadows \& Lumination: Two-illuminant multiple cameras color constancy dataset},
	volume = {224},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S095741742300547X},
	doi = {10.1016/j.eswa.2023.120045},
	shorttitle = {Shadows \& Lumination},
	abstract = {In this paper, we introduce a new large-scale publicly available color constancy dataset which we are calling the Shadows \& Lumination dataset. The dataset contains 2500 minimally processed images from various indoor, outdoor, and night-time scenes. This dataset is {GDPR}-compliant, as we masked out all sensitive private information from the images. Unlike most other color constancy datasets, our dataset contains real-world images with two illuminants is appropriate for multi-illuminant estimation. In addition to the illumination, we provide a binary segmentation mask for each image. In the segmentation mask, we divide the image into two regions, where each region is illuminated by only one of the illuminants. We give an explanation of the methodology used to create the dataset. For dataset creation, we used five cameras: Canon 5D, Canon 550D, Sony Î±300, Panasonic {FZ}1000, and the Motorola one fusion+ mobile camera. Finally, we tested several state-of-the-art illumination estimation and image segmentation models on our dataset. The dataset is publicly available11bit.ly/shal\_dataset Direct link.. This paper also benchmarks several illumination estimation methods as well as several image segmentation methods on our dataset.},
	pages = {120045},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {DomisloviÄ, Ilija and VrÅ¡nak, Donik and SubaÅ¡iÄ, Marko and LonÄariÄ, Sven},
	urldate = {2025-08-28},
	date = {2023-08-15},
	keywords = {Image segmentation, dataset, Color constancy, Image color analysis, Image processing, Multi-illuminant dataset},
	file = {ScienceDirect Snapshot:/Users/alessandroteodori/Zotero/storage/G572Z8JL/S095741742300547X.html:text/html},
}

@article{buzzelli_evaluation_2021,
	title = {On the evaluation of temporal and spatial stability of color constancy algorithms},
	volume = {38},
	issn = {1084-7529, 1520-8532},
	url = {https://opg.optica.org/abstract.cfm?URI=josaa-38-9-1349},
	doi = {10.1364/JOSAA.434860},
	abstract = {Computational color constancy algorithms are commonly evaluated only through angular error analysis on annotated datasets of static images. The widespread use of videos in consumer devices motivated us to define a richer methodology for color constancy evaluation. To this extent, temporal and spatial stability are defined here to determine the degree of sensitivity of color constancy algorithms to variations in the scene that do not depend on the illuminant source, such as moving subjects or a moving camera. Our evaluation methodology is applied to compare several color constancy algorithms on stable sequences belonging to the Gray Ball and Burst Color Constancy video datasets. The stable sequences, identified using a general-purpose procedure, are made available for public download to encourage future research. Our investigation proves the importance of evaluating color constancy algorithms according to multiple metrics, instead of angular error alone. For example, the popular fully convolutional color constancy with confidence-weighted pooling algorithm is consistently the best performing solution for error evaluation, but it is often surpassed in terms of stability by the traditional gray edge algorithm, and by the more recent sensor-independent illumination estimation algorithm.},
	pages = {1349},
	number = {9},
	journaltitle = {Journal of the Optical Society of America A},
	shortjournal = {J. Opt. Soc. Am. A},
	author = {Buzzelli, Marco and Erba, Ilaria},
	urldate = {2025-08-28},
	date = {2021-09-01},
	langid = {english},
	file = {PDF:/Users/alessandroteodori/Zotero/storage/NF9VA5US/Buzzelli e Erba - 2021 - On the evaluation of temporal and spatial stability of color constancy algorithms.pdf:application/pdf},
}
